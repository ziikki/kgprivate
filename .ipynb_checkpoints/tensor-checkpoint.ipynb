{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
<<<<<<< HEAD
    "from sklearn.metrics import mean_absolute_error\n",
=======
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669748</td>\n",
       "      <td>0.515940</td>\n",
       "      <td>0.55421</td>\n",
       "      <td>0.53774</td>\n",
       "      <td>0.47225</td>\n",
       "      <td>0.492200</td>\n",
       "      <td>0.481306</td>\n",
       "      <td>0.756454</td>\n",
       "      <td>0.344502</td>\n",
       "      <td>2152.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484775</td>\n",
       "      <td>0.698278</td>\n",
       "      <td>0.35533</td>\n",
       "      <td>0.40657</td>\n",
       "      <td>0.40666</td>\n",
       "      <td>0.468839</td>\n",
       "      <td>0.458493</td>\n",
       "      <td>0.304350</td>\n",
       "      <td>0.470455</td>\n",
       "      <td>1019.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350956</td>\n",
       "      <td>0.363768</td>\n",
       "      <td>0.58354</td>\n",
       "      <td>0.44352</td>\n",
       "      <td>0.39599</td>\n",
       "      <td>0.341813</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.339244</td>\n",
       "      <td>0.283969</td>\n",
       "      <td>4477.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748243</td>\n",
       "      <td>0.538694</td>\n",
       "      <td>0.54829</td>\n",
       "      <td>0.50420</td>\n",
       "      <td>0.51111</td>\n",
       "      <td>0.711942</td>\n",
       "      <td>0.698722</td>\n",
       "      <td>0.709578</td>\n",
       "      <td>0.776114</td>\n",
       "      <td>907.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321058</td>\n",
       "      <td>0.326430</td>\n",
       "      <td>0.31280</td>\n",
       "      <td>0.39648</td>\n",
       "      <td>0.38016</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.241676</td>\n",
       "      <td>0.261150</td>\n",
       "      <td>0.342082</td>\n",
       "      <td>974.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9   ...        cont6  \\\n",
       "0   0    A    A    A    A    B    A    A    A    A   ...     0.669748   \n",
       "1   1    B    A    A    A    A    B    A    A    A   ...     0.484775   \n",
       "2   2    A    A    A    B    A    A    A    A    A   ...     0.350956   \n",
       "3   3    B    A    A    A    A    B    A    A    A   ...     0.748243   \n",
       "4   4    A    B    A    A    A    A    A    A    B   ...     0.321058   \n",
       "\n",
       "      cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "0  0.515940  0.55421  0.53774  0.47225  0.492200  0.481306  0.756454   \n",
       "1  0.698278  0.35533  0.40657  0.40666  0.468839  0.458493  0.304350   \n",
       "2  0.363768  0.58354  0.44352  0.39599  0.341813  0.352251  0.339244   \n",
       "3  0.538694  0.54829  0.50420  0.51111  0.711942  0.698722  0.709578   \n",
       "4  0.326430  0.31280  0.39648  0.38016  0.245410  0.241676  0.261150   \n",
       "\n",
       "     cont14     loss  \n",
       "0  0.344502  2152.80  \n",
       "1  0.470455  1019.89  \n",
       "2  0.283969  4477.83  \n",
       "3  0.776114   907.11  \n",
       "4  0.342082   974.62  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pml = pd.read_csv('pml_train.csv')\n",
    "print('data loaded')\n",
    "pml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131822, 130)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pml_train_y = pml.loss\n",
    "pml_train_X = pml.drop(columns=['id', 'loss'])\n",
    "pml_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    131822.000000\n",
       "mean       3039.973828\n",
       "std        2913.957535\n",
       "min           5.250000\n",
       "25%        1204.890000\n",
       "50%        2116.585000\n",
       "75%        3865.105000\n",
       "max      121012.250000\n",
       "Name: loss, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pml_train_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10fd678d0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fd42898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pml_train_y.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = pml_train_y<100000\n",
    "# pml_train_y = pml_train_y[idx]\n",
    "# pml_train_X = pml_train_X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131822, 130)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pml_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    131822.000000\n",
       "mean       3039.973828\n",
       "std        2913.957535\n",
       "min           5.250000\n",
       "25%        1204.890000\n",
       "50%        2116.585000\n",
       "75%        3865.105000\n",
       "max      121012.250000\n",
       "Name: loss, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pml_train_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131822, 1111)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pml_train_d_X = pd.get_dummies(pml_train_X)\n",
    "pml_train_d_X.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 7,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56496, 130)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 20,
=======
     "execution_count": 7,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pml_test = pd.read_csv('pml_test_features.csv')\n",
    "pml_test_X = pml_test.drop(columns=['id'])\n",
    "pml_test_X.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 8,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [],
   "source": [
    "# # one-hot encoded test\n",
    "# pml_test_d_X = pd.get_dummies(pml_test)\n",
    "# pml_test_d_X.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 9,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [],
   "source": [
    "# cDrop = [c for c in pml_test_d_X.columns if c not in pml_train_d_X.columns]\n",
    "# print(cDrop)\n",
    "# pml_test_d_X.drop(columns = cDrop, inplace=True)\n",
    "\n",
    "# for c in pml_train_d_X.columns:\n",
    "#     if c not in pml_test_d_X.columns:\n",
    "#         pml_test_d_X[c] = 0\n",
    "# print(pml_test_d_X.shape)\n",
    "# pml_test_d_X.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 10,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [],
   "source": [
    "# pml_train_cont = pml_train_X.filter(regex=(\"cont\\d*\"))\n",
    "# pml_train_cont.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 11,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a correlation matrix between features\n",
    "# x_corr = pml_train_cont.corr()\n",
    "# mask = np.zeros_like(x_corr, dtype=np.bool)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "# f, ax = plt.subplots(figsize=(11, 9))\n",
    "# cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "# sns.heatmap(x_corr, mask=mask, vmax=1, cmap=cmap, center=0,\n",
    "#             square=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 12,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_op(col):\n",
    "    return col.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 13,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_op(code):\n",
    "    num = 0\n",
    "    for alpha in code:\n",
    "        num *= 26\n",
    "        num += ord(alpha) - ord('A') + 1\n",
    "    return num\n",
    "\n",
    "def to_digit(col):\n",
    "    return col.apply(digit_op)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 14,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27\n",
       "1    54\n",
       "2     1\n",
       "dtype: int64"
      ]
     },
<<<<<<< HEAD
     "execution_count": 27,
=======
     "execution_count": 14,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_digit(pd.Series(['AA','BB','A']))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 15,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_X_to_digit(orig_train_X):\n",
    "    c_X = orig_train_X.copy()\n",
    "    tmp = orig_train_X.select_dtypes(exclude=['float64','int64'])\n",
    "    # tmp = pd.Categorical(tmp)\n",
    "\n",
    "    c_X.loc[:, tmp.columns] = tmp.apply(lambda col: col.astype('category').cat.codes)\n",
    "    return c_X"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 16,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data encoded\n"
     ]
    }
   ],
   "source": [
    "pml_train_c_X = encode_X_to_digit(pml_train_X)\n",
    "pml_test_c_X = encode_X_to_digit(pml_test_X)\n",
    "print('data encoded')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 17,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577339</td>\n",
       "      <td>0.669748</td>\n",
       "      <td>0.515940</td>\n",
       "      <td>0.55421</td>\n",
       "      <td>0.53774</td>\n",
       "      <td>0.47225</td>\n",
       "      <td>0.492200</td>\n",
       "      <td>0.481306</td>\n",
       "      <td>0.756454</td>\n",
       "      <td>0.344502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.484775</td>\n",
       "      <td>0.698278</td>\n",
       "      <td>0.35533</td>\n",
       "      <td>0.40657</td>\n",
       "      <td>0.40666</td>\n",
       "      <td>0.468839</td>\n",
       "      <td>0.458493</td>\n",
       "      <td>0.304350</td>\n",
       "      <td>0.470455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499798</td>\n",
       "      <td>0.350956</td>\n",
       "      <td>0.363768</td>\n",
       "      <td>0.58354</td>\n",
       "      <td>0.44352</td>\n",
       "      <td>0.39599</td>\n",
       "      <td>0.341813</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.339244</td>\n",
       "      <td>0.283969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.748243</td>\n",
       "      <td>0.538694</td>\n",
       "      <td>0.54829</td>\n",
       "      <td>0.50420</td>\n",
       "      <td>0.51111</td>\n",
       "      <td>0.711942</td>\n",
       "      <td>0.698722</td>\n",
       "      <td>0.709578</td>\n",
       "      <td>0.776114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491114</td>\n",
       "      <td>0.321058</td>\n",
       "      <td>0.326430</td>\n",
       "      <td>0.31280</td>\n",
       "      <td>0.39648</td>\n",
       "      <td>0.38016</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.241676</td>\n",
       "      <td>0.261150</td>\n",
       "      <td>0.342082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10    ...     \\\n",
       "0     0     0     0     0     1     0     0     0     0      0    ...      \n",
       "1     1     0     0     0     0     1     0     0     0      0    ...      \n",
       "2     0     0     0     1     0     0     0     0     0      0    ...      \n",
       "3     1     0     0     0     0     1     0     0     0      0    ...      \n",
       "4     0     1     0     0     0     0     0     0     1      0    ...      \n",
       "\n",
       "      cont5     cont6     cont7    cont8    cont9   cont10    cont11  \\\n",
       "0  0.577339  0.669748  0.515940  0.55421  0.53774  0.47225  0.492200   \n",
       "1  0.281143  0.484775  0.698278  0.35533  0.40657  0.40666  0.468839   \n",
       "2  0.499798  0.350956  0.363768  0.58354  0.44352  0.39599  0.341813   \n",
       "3  0.281143  0.748243  0.538694  0.54829  0.50420  0.51111  0.711942   \n",
       "4  0.491114  0.321058  0.326430  0.31280  0.39648  0.38016  0.245410   \n",
       "\n",
       "     cont12    cont13    cont14  \n",
       "0  0.481306  0.756454  0.344502  \n",
       "1  0.458493  0.304350  0.470455  \n",
       "2  0.352251  0.339244  0.283969  \n",
       "3  0.698722  0.709578  0.776114  \n",
       "4  0.241676  0.261150  0.342082  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 30,
=======
     "execution_count": 17,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pml_train_c_X.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 18,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generate a correlation matrix between features\n",
    "# x_corr = pml_train_c_X.corr()\n",
    "# mask = np.zeros_like(x_corr, dtype=np.bool)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "# f, ax = plt.subplots(figsize=(22, 18))\n",
    "# cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "# sns.heatmap(x_corr, mask=mask, vmax=1, cmap=cmap, center=0,\n",
    "#             square=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
=======
   "execution_count": 19,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standardization\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# pml_train_c_X = scaler.transform(pml_train_c_X)\n",
    "# pml_test_c_X = scaler.transform(pml_test_c_X)\n",
    "\n",
    "# pml_test_c_X.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56496, 130)\n"
     ]
    }
   ],
   "source": [
    "# normalize\n",
    "normalizer = MinMaxScaler().fit(pml_train_c_X)\n",
    "pml_train_c_X = normalizer.transform(pml_train_c_X)\n",
    "pml_test_c_X = normalizer.transform(pml_test_c_X)\n",
    "\n",
    "print(pml_test_c_X.shape)"
=======
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56496, 130)\n"
     ]
    }
   ],
   "source": [
    "# normalize\n",
    "normalizer = MinMaxScaler().fit(pml_train_c_X)\n",
    "pml_train_c_X = normalizer.transform(pml_train_c_X)\n",
    "pml_test_c_X = normalizer.transform(pml_test_c_X)\n",
    "\n",
    "print(pml_test_c_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kBest = SelectKBest( k=50)\n",
    "pml_train_sfs_X = kBest.fit_transform(pml_train_c_X, pml_train_y)\n",
    "pml_test_sfs_X = kBest.transform(pml_test_c_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56496, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pml_test_sfs_X.shape"
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kBest = SelectKBest( k=50)\n",
    "# pml_train_sfs_X = kBest.fit_transform(pml_train_c_X, pml_train_y)\n",
    "# pml_test_sfs_X = kBest.transform(pml_test_c_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pml_test_sfs_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
=======
   "execution_count": 23,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data prep finished\n"
     ]
    }
   ],
   "source": [
    "# test/train split\n",
    "split_train_X = pml_train_c_X\n",
    "split_test_X = pml_test_c_X\n",
    "val_train_X, val_test_X, val_train_y, val_test_y = train_test_split(split_train_X, pml_train_y, random_state=2018, test_size=0.05)\n",
    "print('data prep finished')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 47,
=======
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_score(clf, X, y):\n",
    "    prd_y = clf.predict(X)\n",
    "    return np.sqrt(np.sum((prd_y-y)**2)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline:\n",
<<<<<<< HEAD
    "def try_clf(clf, clf_name='', train_X = val_train_X, train_y = val_train_y, test_X = val_test_X, test_y = val_test_y, save_clf=False):\n",
    "    print('start training ' + clf_name )\n",
    "    clf.fit(train_X, train_y)\n",
    "    print( str(train_X.shape) + \"data trained,\" + str(test_X.shape) + \" data tested\")\n",
    "    if save_clf:\n",
    "        from sklearn.externals import joblib\n",
    "        joblib.dump(clf, '%s.pkl'%clf_name) \n",
    "#     print(clf_name + ' train :' + str(clf.score(train_X, train_y)))\n",
    "#     print(clf_name + ' test  :' + str(clf.score(test_X, test_y)))\n",
    "    print('%s train : %.4f' % (clf_name, mean_absolute_error(train_y, clf.predict(train_X))))\n",
    "    print('%s train : %.4f' % (clf_name, mean_absolute_error(test_y, clf.predict(test_X))))\n",
=======
    "def try_clf(clf, clf_name='', train_X = val_train_X, train_y = val_train_y, test_X = val_test_X, test_y = val_test_y):\n",
    "    print('start training ' + clf_name )\n",
    "    clf.fit(train_X, train_y)\n",
    "    print(clf_name + ' train :' + str(clf.score(train_X, train_y)))\n",
    "    print(clf_name + ' test  :' + str(clf.score(test_X, test_y)))\n",
    "    print(mse_score(clf, test_X, test_y))\n",
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
=======
   "execution_count": 26,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_clf(clf, clf_name='clf', pml_X = split_test_X):\n",
    "    ans = clf.predict(pml_X)\n",
<<<<<<< HEAD
    "    filepath = 'csv/' + clf_name + '.csv'\n",
=======
    "    filename = clf_name + '.csv'\n",
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
    "    pd.DataFrame({'id':pml_test['id'], \n",
    "          'loss':ans}).to_csv(filepath,index = False)\n",
    "    print('exported as ' + filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tune_para_my(clf, train_X, train_y, test_X, test_y):\n",
    "#     clf = try_clf(clf, 'svr rbf',svr_train_X,  svr_train_y, svr_test_X, svr_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_para_cv(estimator, X, y, parameter_name ,parameters, k_fold = 10):\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    tuned_parameters = [{parameter_name: parameters}]\n",
    "    n_folds = k_fold\n",
    "\n",
    "    clf = GridSearchCV(estimator, tuned_parameters, cv=n_folds, refit=False)\n",
    "    clf.fit(X, y)\n",
    "    scores = clf.cv_results_['mean_test_score']\n",
    "    scores_std = clf.cv_results_['std_test_score']\n",
    "    plt.figure().set_size_inches(8, 6)\n",
    "\n",
    "    plt.plot(parameters, scores)\n",
    "\n",
    "    # plot error lines showing +/- std. errors of the scores\n",
    "    std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "    plt.plot(parameters, scores + std_error, 'b--')\n",
    "    plt.plot(parameters, scores - std_error, 'b--')\n",
    "\n",
    "    # alpha=0.2 controls the translucency of the fill color\n",
    "    #plt.fill_between(cc, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "    plt.ylabel('CV score +/- std error')\n",
    "    plt.xlabel(parameter_name)\n",
    "    plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
    "    plt.xlim([parameters[0], parameters[-1]])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def print_cv(scores):\n",
    "    print(scores)\n",
    "    print('Mean:\\t %f' % np.mean(scores))\n",
    "    print('Var :\\t %f' % np.var(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_para_my(clf, train_X, train_y, test_X, test_y)\n",
    "    clf = \n",
    "    clf = try_clf(clf, 'svr rbf',svr_train_X,  svr_train_y, svr_test_X, svr_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_para_cv(estimator, X, y, parameter_name ,parameters, k_fold = 10):\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    tuned_parameters = [{parameter_name: parameters}]\n",
    "    n_folds = k_fold\n",
    "\n",
    "    clf = GridSearchCV(estimator, tuned_parameters, cv=n_folds, refit=False)\n",
    "    clf.fit(X, y)\n",
    "    scores = clf.cv_results_['mean_test_score']\n",
    "    scores_std = clf.cv_results_['std_test_score']\n",
    "    plt.figure().set_size_inches(8, 6)\n",
    "\n",
    "    plt.plot(parameters, scores)\n",
    "\n",
    "    # plot error lines showing +/- std. errors of the scores\n",
    "    std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "    plt.plot(parameters, scores + std_error, 'b--')\n",
    "    plt.plot(parameters, scores - std_error, 'b--')\n",
    "\n",
    "    # alpha=0.2 controls the translucency of the fill color\n",
    "    #plt.fill_between(cc, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "    plt.ylabel('CV score +/- std error')\n",
    "    plt.xlabel(parameter_name)\n",
    "    plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
    "    plt.xlim([parameters[0], parameters[-1]])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def print_cv(scores):\n",
    "    print(scores)\n",
    "    print('Mean:\\t %f' % np.mean(scores))\n",
    "    print('Var :\\t %f' % np.var(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 28,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training \n",
<<<<<<< HEAD
      "(125229, 130)data trained,(6591, 130) data tested\n",
      " train :1326.9753751293504\n",
      " test :1356.9860170673007\n"
=======
      " train :0.48288038512837705\n",
      " test  :0.45985514773794783\n",
      "2122.736654367221\n"
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
     ]
    }
   ],
   "source": [
    "lin = LinearRegression()\n",
    "lin = try_clf(lin)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 29,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported as lin_default.csv\n"
     ]
    }
   ],
   "source": [
    "use_clf(lin, 'lin_default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_X = pml_train_c_X\n",
    "svr_y = pml_train_y\n",
    "pml_svr_test_X = pml_test_c_X\n",
=======
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_keep = np.array([False, False, False, False, False, False, False,  True, False,\n",
    "       False, False, False, False, False,  True, False, False,  True,\n",
    "       False, False,  True,  True, False, False, False, False, False,\n",
    "       False,  True,  True,  True, False, False, False, False, False,\n",
    "       False, False,  True, False, False,  True, False, False,  True,\n",
    "       False, False, False, False, False, False, False, False,  True,\n",
    "       False,  True, False, False, False,  True, False, False, False,\n",
    "        True, False, False, False,  True,  True,  True, False, False,\n",
    "       False, False, False, False,  True, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_X = pml_train_c_X[:,var_keep==False]\n",
    "svr_y = pml_train_y\n",
    "pml_svr_test_X = pml_test_c_X[:,var_keep]\n",
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
    "\n",
    "# svr_train_X, svr_test_X, svr_train_y, svr_test_y = train_test_split(svr_X, svr_y, random_state=2018, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.choice(svr_X.shape[0], 10000, replace=False)\n",
    "svr_X = svr_X[idx, :]\n",
    "svr_y = svr_y.reshape(-1,1)[idx, :].squeeze()"
=======
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.shape"
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_train_X, svr_test_X, svr_train_y, svr_test_y = train_test_split(svr_X, svr_y, random_state=2018, test_size=0.2)"
=======
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(svr_X.shape[0], 10000, replace=False)\n",
    "svr_X = svr_X[idx, :]\n",
    "svr_y = svr_y.reshape(-1,1)[idx, :].squeeze()"
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_train_X, svr_test_X, svr_train_y, svr_test_y = train_test_split(svr_X, svr_y, random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(10000, 130)"
      ]
     },
     "execution_count": 44,
=======
       "(10000, 111)"
      ]
     },
     "execution_count": 49,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_X.shape"
<<<<<<< HEAD
=======
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training svr rbf\n",
      "svr rbf train :-0.10531409562258331\n",
      "svr rbf test  :-0.09077491843494645\n",
      "3036.266110219221\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(kernel='poly', gamma = 0.01, C=0.1, degree=2, tol = 0.1, cache_size=300)\n",
    "svr = try_clf(svr, 'svr rbf',svr_train_X,  svr_train_y, svr_test_X, svr_test_y)"
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 68,
=======
   "execution_count": null,
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   "metadata": {},
   "outputs": [],
   "source": [
    "krnl = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training svr_sigmoid\n",
      "(8000, 130)data trained,(2000, 130) data tested\n",
      "svr_sigmoid train :2953.998893266021\n",
      "svr_sigmoid train :3013.529886762934\n",
      "SVR(C=0.1, cache_size=300, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='sigmoid', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "svr = SVR(kernel=krnl, C=0.1, cache_size=300)\n",
    "svr = try_clf(svr, 'svr_'+krnl,svr_train_X,  svr_train_y, svr_test_X, svr_test_y)\n",
    "print(svr)"
=======
    "use_clf(svr,'svr_default',pml_svr_test_X)"
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported as svr_default.csv\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "use_clf(svr,'svr_default',pml_svr_test_X)"
=======
    "pml_train_y.shape"
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131822,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pml_train_y.shape"
=======
   "outputs": [],
   "source": [
    "dgr = np.arange(2,5)\n",
    "svr = SVR( gamma = 0.01, C=0.1, tol = 0.1, cache_size=300)\n",
    "tune_para_cv(svr, split_train_X, pml_train_y, 'degree', dgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tree"
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------degree 4-------\n",
      "start training svr_4_degree\n",
      "(8000, 111)data trained,(2000, 111) data tested\n",
      "svr_4_degree train :3155.4533380682897\n",
      "svr_4_degree train :2955.770435222077\n",
      "exported as csv/svr_4_degree.csv\n",
      "------degree 5-------\n",
      "start training svr_5_degree\n",
      "(8000, 111)data trained,(2000, 111) data tested\n",
      "svr_5_degree train :3155.4602809414237\n",
      "svr_5_degree train :2955.777607865198\n",
      "exported as csv/svr_5_degree.csv\n"
     ]
    }
   ],
   "source": [
    "svr_degree_scores = []\n",
    "degree_range = np.arange(4,6)\n",
    "for dgr in degree_range:\n",
    "    print('------degree '+ str(dgr) +'-------')\n",
    "    clf_name = 'svr_'+str(dgr)+'_degree'\n",
    "    degree_svr = SVR(kernel=krnl, degree = dgr, C=0.1, cache_size=300)\n",
    "    degree_svr = try_clf(degree_svr, clf_name,svr_train_X,  svr_train_y, svr_test_X, svr_test_y)\n",
    "    print(degree_svr)\n",
    "    svr_degree_scores.append(mse_score(degree_svr, svr_test_X, svr_test_y))\n",
    "    use_clf(svr,clf_name,pml_svr_test_X)\n",
    "    "
=======
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#. ec2-spotter/fast_ai/create_vpc.sh"
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2802.8827491366446, 2802.8827491366446, 2802.8827491366446]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_degree = degree_range[svr_degree_scores.index(min(svr_degree_scores))]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00390625, 0.01104854, 0.03125   , 0.08838835, 0.25      ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-8,-2,num = 5,base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------degree 2-------\n",
      "start training svr rbf\n",
      "(9000, 111)data trained,(1000, 111) data tested\n",
      "svr rbf train :-0.10129682797310968\n",
      "svr rbf test  :-0.08693442373835603\n",
      "2803.1550472852896\n",
      "SVR(C=0.1, cache_size=300, coef0=0.0, degree=2, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.1, verbose=False)\n",
      "exported as svr_2_degree.csv\n",
      "------degree 3-------\n",
      "start training svr rbf\n",
      "(9000, 111)data trained,(1000, 111) data tested\n",
      "svr rbf train :-0.10129682797310968\n",
      "svr rbf test  :-0.08693442373835603\n",
      "2803.1550472852896\n",
      "SVR(C=0.1, cache_size=300, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.1, verbose=False)\n",
      "exported as svr_3_degree.csv\n",
      "------degree 4-------\n",
      "start training svr rbf\n",
      "(9000, 111)data trained,(1000, 111) data tested\n",
      "svr rbf train :-0.10129682797310968\n",
      "svr rbf test  :-0.08693442373835603\n",
      "2803.1550472852896\n",
      "SVR(C=0.1, cache_size=300, coef0=0.0, degree=4, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.1, verbose=False)\n",
      "exported as svr_4_degree.csv\n"
     ]
    }
   ],
   "source": [
    "svr_degree_scores = []\n",
    "degree_range = np.arange(2,5)\n",
    "for dgr in degree_range:\n",
    "    print('------degree '+ str(dgr) +'-------')\n",
    "    clf_name = 'svr_'+str(dgr)+'_degree'\n",
    "    degree_svr = SVR(kernel=krnl, degree = best_degree, C=0.1, tol = 0.1, cache_size=300)\n",
    "    degree_svr = try_clf(degree_svr, 'svr rbf',svr_train_X,  svr_train_y, svr_test_X, svr_test_y)\n",
    "    print(degree_svr)\n",
    "    svr_degree_scores.append(mse_score(degree_svr, svr_test_X, svr_test_y))\n",
    "    use_clf(svr,clf_name,pml_svr_test_X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2803.1550472852896, 2803.1550472852896, 2803.1550472852896]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_degree_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------gamma 0.00390625-------\n",
      "start training svr_0.00390625_gamma\n",
      "(8000, 111)data trained,(2000, 111) data tested\n",
      "svr_0.00390625_gamma train :-0.10275250244694689\n",
      "svr_0.00390625_gamma test  :-0.10008809537097818\n",
      "2954.89382826394\n",
      "SVR(C=0.1, cache_size=300, coef0=0.0, degree=2, epsilon=0.1, gamma=0.00390625,\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.1, verbose=False)\n",
      "exported as svr_0.00390625_gamma.csv\n",
      "------gamma 0.011048543456039806-------\n",
      "start training svr_0.011048543456039806_gamma\n",
      "(8000, 111)data trained,(2000, 111) data tested\n",
      "svr_0.011048543456039806_gamma train :-0.1018666528788843\n",
      "svr_0.011048543456039806_gamma test  :-0.0990716487142127\n",
      "2953.5283985001306\n",
      "SVR(C=0.1, cache_size=300, coef0=0.0, degree=2, epsilon=0.1,\n",
      "  gamma=0.011048543456039806, kernel='rbf', max_iter=-1, shrinking=True,\n",
      "  tol=0.1, verbose=False)\n",
      "exported as svr_0.011048543456039806_gamma.csv\n",
      "------gamma 0.03125-------\n",
      "start training svr_0.03125_gamma\n",
      "(8000, 111)data trained,(2000, 111) data tested\n",
      "svr_0.03125_gamma train :-0.09979105865532412\n",
      "svr_0.03125_gamma test  :-0.09671804869398515\n",
      "2950.364296315512\n",
      "SVR(C=0.1, cache_size=300, coef0=0.0, degree=2, epsilon=0.1, gamma=0.03125,\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.1, verbose=False)\n",
      "exported as svr_0.03125_gamma.csv\n",
      "------gamma 0.08838834764831845-------\n",
      "start training svr_0.08838834764831845_gamma\n",
      "(8000, 111)data trained,(2000, 111) data tested\n",
      "svr_0.08838834764831845_gamma train :-0.09849118310914395\n",
      "svr_0.08838834764831845_gamma test  :-0.09520466462030819\n",
      "2948.327959011193\n",
      "SVR(C=0.1, cache_size=300, coef0=0.0, degree=2, epsilon=0.1,\n",
      "  gamma=0.08838834764831845, kernel='rbf', max_iter=-1, shrinking=True,\n",
      "  tol=0.1, verbose=False)\n",
      "exported as svr_0.08838834764831845_gamma.csv\n",
      "------gamma 0.25-------\n",
      "start training svr_0.25_gamma\n",
      "(8000, 111)data trained,(2000, 111) data tested\n",
      "svr_0.25_gamma train :-0.10054089683847334\n",
      "svr_0.25_gamma test  :-0.09759730667944844\n",
      "2951.546738620934\n",
      "SVR(C=0.1, cache_size=300, coef0=0.0, degree=2, epsilon=0.1, gamma=0.25,\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.1, verbose=False)\n",
      "exported as svr_0.25_gamma.csv\n"
     ]
    }
   ],
   "source": [
    "svr_gamma_scores = []\n",
    "gamma_range = np.logspace(-8,-2,num = 5,base=2)\n",
    "for gm in gamma_range:\n",
    "    print('------gamma '+ str(gm) +'-------')\n",
    "    clf_name = 'svr_'+str(gm)+'_gamma'\n",
    "    gm_svr = SVR(kernel=krnl, degree = 2, gamma = 0.08, C=0.1, tol = 0.1, cache_size=300)\n",
    "    gm_svr = try_clf(gm_svr, clf_name,svr_train_X,  svr_train_y, svr_test_X, svr_test_y)\n",
    "    print(gm_svr)\n",
    "    svr_gamma_scores.append(mse_score(gm_svr, svr_test_X, svr_test_y))\n",
    "    use_clf(gm_svr,clf_name,pml_svr_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2954.89382826394,\n",
       " 2953.5283985001306,\n",
       " 2950.364296315512,\n",
       " 2948.327959011193,\n",
       " 2951.546738620934]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_gamma_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gamma = gamma_range[svr_gamma_scores.index(min(svr_gamma_scores))]"
=======
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training rf\n",
      "rf train :0.37759226016599257\n",
      "rf test  :0.35921548261220154\n",
      "187717.86349091865\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=20, max_leaf_nodes = 20, \n",
    "                            random_state = 2018)\n",
    "rf = try_clf(rf, 'rf',,,,,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported as rf_20tree_20maxnodes.csv\n"
     ]
    }
   ],
   "source": [
    "use_clf(rf,'csv/rf_20tree_20maxnode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training rf\n",
      "rf train :0.5312358252664292\n",
      "rf test  :0.4477747364011039\n",
      "174264.02201728785\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestRegressor(n_estimators=10, max_leaf_nodes = 100, \n",
    "                            random_state = 2018)\n",
    "rf2 = try_clf(rf2, 'rf2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported as rf_10tree_100maxnodes.csv\n"
     ]
    }
   ],
   "source": [
    "use_clf(rf2,'csv/rf_10tree_100maxnode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training rf3\n",
      "rf3 train :0.542120449658501\n",
      "rf3 test  :0.45601904833664086\n",
      "172958.3143448042\n"
     ]
    }
   ],
   "source": [
    "rf3 = RandomForestRegressor(n_estimators=30, max_leaf_nodes = 120, \n",
    "                            min_samples_split=10, random_state = 2018)\n",
    "rf3 = try_clf(rf3, 'rf3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported as csv/rf_30tree_120maxnodes.csv\n"
     ]
    }
   ],
   "source": [
    "use_clf(rf3,'csv/rf_30tree_120maxnode')"
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_prd_y = rf3.predict(val_train_y)\n",
    "temp_y = val_test_y\n",
    "plt.scatter(temp_prd_y,temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "       False,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False,  True, False, False,  True, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False,  True,  True,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf3.feature_importances_ == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training rf4\n",
      "rf4 train :0.5357728740110539\n",
      "rf4 test  :0.44944416723412933\n",
      "174000.4140706748\n"
     ]
    }
   ],
   "source": [
    "rf4 = RandomForestRegressor(n_estimators=50, max_leaf_nodes = 100, \n",
    "                             min_impurity_decrease=0.1, random_state = 2018)\n",
    "rf4 = try_clf(rf4, 'rf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "gamma_range = np.logspace(-8,-2,num = 5,base=2)\n",
    "\n",
    "clf = GridSearchCV(estimator, tuned_parameters, cv=n_folds, refit=False)\n",
    "clf.fit(X, y)\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "scores_std = clf.cv_results_['std_test_score']\n"
=======
    "use_clf(rf4,'csv/rf_50tree_100maxnode')"
>>>>>>> cebd5cb015374117e70cc5a5a471d3fcbfb8d1db
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------final run-------\n",
      "start training tuned_svr\n",
      "(125230, 130)data trained,(6592, 130) data tested\n",
      "tuned_svr train :-0.03428160748999298\n",
      "tuned_svr test  :-0.02709801218926477\n",
      "2927.1632414645233\n",
      "exported as tuned_svr.csv\n"
     ]
    }
   ],
   "source": [
    "print('------final run-------')\n",
    "clf_name = 'tuned_svr'\n",
    "tuned_svr = SVR(kernel=krnl, degree = 2, gamma = 0.08, C=0.1, tol = 0.1, cache_size=300)\n",
    "tuned_svr = try_clf(tuned_svr, clf_name)\n",
    "use_clf(tuned_svr,clf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# s = pickle.dumps(clf)\n",
    "# clf2 = pickle.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tuned_svr.pkl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(tuned_svr, 'tuned_svr.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#. ec2-spotter/fast_ai/create_vpc.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-32-722e557fb230>\", line 2, in <module>\n",
      "    rf = try_clf(rf, 'rf')\n",
      "  File \"<ipython-input-28-135e508d2996>\", line 4, in try_clf\n",
      "    clf.fit(train_X, train_y)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/ensemble/forest.py\", line 328, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 789, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 699, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 638, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 635, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\", line 551, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=10,  criterion = 'mae', n_jobs=3, random_state = 2018)\n",
    "rf = try_clf(rf, 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_clf(rf,'rf_20tree_20maxnode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestRegressor(n_estimators=100, criterion = 'mae',\n",
    "                            max_leaf_nodes = 120, random_state = 2018)\n",
    "rf2 = try_clf(rf2, 'rf2', save_clf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_clf(rf2,'rf_100tree_120maxnode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestRegressor(n_estimators=30, max_leaf_nodes = 120, criterion = 'mae',\n",
    "                            min_samples_split=10, random_state = 2018)\n",
    "rf3 = try_clf(rf3, 'rf3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_clf(rf3,'rf_30tree_120maxnode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_prd_y = rf2.predict(val_train_X)\n",
    "temp_y = val_train_y\n",
    "plt.scatter(temp_prd_y,temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3.feature_importances_ == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf4 = RandomForestRegressor(n_estimators=50, max_leaf_nodes = 100, criterion = 'mae',\n",
    "                             min_impurity_decrease=0.1, random_state = 2018)\n",
    "rf4 = try_clf(rf4, 'rf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_clf(rf4,'rf_50tree_100maxnode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf5 = RandomForestRegressor(n_estimators=100, criterion = 'mae',\n",
    "                            max_leaf_nodes = 120, random_state = 2018)\n",
    "rf5 = try_clf(rf5, 'rf5', save_clf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_clf(rf5,'rf_64tree_120maxnode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 'AB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in reversed(c):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({'a':['A','B','C','B'],\n",
    "             'b':['DC','BD','BF','CC']})\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op(col):\n",
    "    return col.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniques = np.sort(pd.unique(temp.values.ravel()))\n",
    "# temp.apply(lambda x: x.astype('category', categories=uniques))\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(temp.values.flat)\n",
    "\n",
    "# Convert to digits.\n",
    "temp = temp.apply(le.transform)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training gbr\n",
      "(8000, 130)data trained,(2000, 130) data tested\n",
      "gbr train : 1178.4983\n",
      "gbr train : 1303.0161\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 100, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'lad'}\n",
    "gbr_test = GradientBoostingRegressor(**params)\n",
    "gbr_test = try_clf(gbr, 'gbr', svr_train_X,  svr_train_y, svr_test_X, svr_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_degree_scores = []\n",
    "degree_range = np.arange(2,5)\n",
    "for dgr in degree_range:\n",
    "    print('------degree '+ str(dgr) +'-------')\n",
    "    clf_name = 'svr_'+str(dgr)+'_degree'\n",
    "    degree_svr = SVR(kernel=krnl, degree = best_degree, C=0.1, tol = 0.1, cache_size=300)\n",
    "    degree_svr = try_clf(degree_svr, 'svr rbf',svr_train_X,  svr_train_y, svr_test_X, svr_test_y)\n",
    "    print(degree_svr)\n",
    "    svr_degree_scores.append(mse_score(degree_svr, svr_test_X, svr_test_y))\n",
    "    use_clf(svr,clf_name,pml_svr_test_X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_gbr(estimator, X, y, parameter_name ,parameters, k_fold = 10):\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    tuned_parameters = [{parameter_name: parameters}]\n",
    "    n_folds = k_fold\n",
    "\n",
    "    clf = GridSearchCV(estimator, tuned_parameters, cv=n_folds, refit=False)\n",
    "    clf.fit(X, y)\n",
    "    scores = clf.cv_results_['mean_test_score']\n",
    "    scores_std = clf.cv_results_['std_test_score']\n",
    "    plt.figure().set_size_inches(8, 6)\n",
    "\n",
    "    plt.plot(parameters, scores)\n",
    "\n",
    "    # plot error lines showing +/- std. errors of the scores\n",
    "    std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "    plt.plot(parameters, scores + std_error, 'b--')\n",
    "    plt.plot(parameters, scores - std_error, 'b--')\n",
    "\n",
    "    # alpha=0.2 controls the translucency of the fill color\n",
    "    #plt.fill_between(cc, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "    plt.ylabel('CV score +/- std error')\n",
    "    plt.xlabel(parameter_name)\n",
    "    plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
    "    plt.xlim([parameters[0], parameters[-1]])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def print_cv(scores):\n",
    "    print(scores)\n",
    "    print('Mean:\\t %f' % np.mean(scores))\n",
    "    print('Var :\\t %f' % np.var(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training gbr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-31a28d0b1249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           'learning_rate': 0.01, 'loss': 'lad'}\n\u001b[1;32m      3\u001b[0m \u001b[0mgbr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgbr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gbr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-c9b311586b07>\u001b[0m in \u001b[0;36mtry_clf\u001b[0;34m(clf, clf_name, train_X, train_y, test_X, test_y, save_clf)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtry_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_train_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_test_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_test_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_clf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start training '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclf_name\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"data trained,\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" data tested\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_clf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 788\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'lad'}\n",
    "gbr = GradientBoostingRegressor(**params)\n",
    "gbr = try_clf(gbr, 'gbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_clf(rf,'rf_20tree_20maxnode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_prd_y = rf2.predict(val_train_X)\n",
    "temp_y = val_train_y\n",
    "plt.scatter(temp_prd_y,temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Plot training deviance\n",
    "\n",
    "# compute test set deviance\n",
    "test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "\n",
    "for i, y_pred in enumerate(gbr.staged_predict(val_test_X)):\n",
    "    test_score[i] = gbr.loss_(val_test_y, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, gbr.train_score_, 'b-',\n",
    "         label='Training Set Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n",
    "         label='Test Set Deviance')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('Deviance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Plot feature importance\n",
    "feature_importance = gbr.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, boston.feature_names[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
